{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])\n",
    "df = df.drop(columns=['Payment Plan'])\n",
    "df = df.drop(columns=['Accounts Delinquent'])\n",
    "df = df.drop(columns=['Batch Enrolled'])\n",
    "df =df.drop(columns=['Application Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['debt consolidation', 'credit card refinancing',\n",
       "       'home improvement', 'credit consolidation', 'green loan', 'other',\n",
       "       'moving and relocation', 'credit cards', 'medical expenses',\n",
       "       'refinance', 'credit card consolidation', 'lending club',\n",
       "       'debt consolidation loan', 'major purchase', 'vacation',\n",
       "       'business', 'credit card payoff', 'credit card',\n",
       "       'credit card refi', 'personal loan', 'cc refi', 'consolidate',\n",
       "       'medical', 'loan 1', 'consolidation', 'card consolidation',\n",
       "       'car financing', 'debt', 'home buying', 'freedom', 'consolidated',\n",
       "       'get out of debt', 'consolidation loan', 'dept consolidation',\n",
       "       'personal', 'cards', 'bathroom', 'refi', 'credit card loan',\n",
       "       'credit card debt', 'house', 'debt consolidation 2013',\n",
       "       'debt loan', 'cc refinance', 'home', 'cc consolidation',\n",
       "       'credit card refinance', 'credit loan', 'payoff',\n",
       "       'bill consolidation', 'credit card paydown', 'credit card pay off',\n",
       "       'get debt free', 'myloan', 'credit pay off', 'my loan', 'loan',\n",
       "       'bill payoff', 'cc-refinance', 'debt reduction', 'medical loan',\n",
       "       'wedding loan', 'credit', 'pay off bills', 'refinance loan',\n",
       "       'debt payoff', 'car loan', 'pay off', 'pool', 'credit payoff',\n",
       "       'credit card refinance loan', 'cc loan', 'debt free', 'conso',\n",
       "       'home improvement loan', 'loan consolidation', 'lending loan',\n",
       "       'relief', 'cc', 'loan1', 'getting ahead', 'home loan', 'bills'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Loan Title'] = df['Loan Title'].str.lower()\n",
    "len(df['Loan Title'].unique())\n",
    "df['Loan Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {'Loan Title':{'debt consolidation':'debt consolidation', \\\n",
    "                'debt consolidation loan':'debt consolidation', \\\n",
    "                'debt consolidation 2013':'debt consolidation', \\\n",
    "                'dept consolidation':'debt consolidation' ,\n",
    "                'credit card refinancing':'credit card refinancing', \\\n",
    "                'refinance':'credit card refinancing', \\\n",
    "                'cc refinance':'credit card refinancing',\\\n",
    "                'credit card refinance':'credit card refinancing',\\\n",
    "                'cc-refinance':'credit card refinancing', \\\n",
    "                'refinance loan':'credit card refinancing', \\\n",
    "                'credit card refinance loan':'credit card refinancing',\\\n",
    "                'credit card refi':'credit card refinancing', \\\n",
    "                'cc refi':'credit card refinancing', \\\n",
    "                'refi':'credit card refinancing'  ,\n",
    "                'home improvement':'home improvement',\\\n",
    "                'home improvement loan':'home improvement',\\\n",
    "                'bathroom':'home improvement',\\\n",
    "                'pool':'home improvement' ,\n",
    "                'home buying':'home buy',\\\n",
    "                'house':'home buy',\\\n",
    "                'home':'home buy',\\\n",
    "                'home loan':'home buy' ,\n",
    "                'credit consolidation':'credit consolidation',\\\n",
    "                'consolidation loan':'credit consolidation',\\\n",
    "                'cc consolidation':'credit consolidation',\\\n",
    "                'conso':'credit consolidation',\\\n",
    "                'credit card consolidation':'credit consolidation',\\\n",
    "                'card consolidation':'credit consolidation',\\\n",
    "                'loan consolidation':'credit consolidation',\\\n",
    "                'consolidate':'credit consolidation',\\\n",
    "                'consolidated':'credit consolidation' ,\n",
    "                'medical':'medical purpose',\\\n",
    "                'medical expenses':'medical purpose',\\\n",
    "                'medical loan':'medical purpose'  ,\n",
    "                'lending club' : 'lending purpose' , \\\n",
    "                'lending loan' : 'lending purpose'  ,\n",
    "                'business' : 'business purpose' , \\\n",
    "                'green loan' : 'business purpose' , \\\n",
    "                'moving and relocation' : 'business purpose'  , \\\n",
    "                'credit cards' : 'credit cards payoff' , \\\n",
    "                'credit card' : 'credit cards payoff' , \\\n",
    "                'credit card loan' : 'credit cards payoff' , \\\n",
    "                'credit' : 'credit cards payoff' , \\\n",
    "                'credit card debt' : 'credit cards payoff' , \\\n",
    "                'cc loan' : 'credit cards payoff' , \\\n",
    "                'cc' : 'credit cards payoff' , \\\n",
    "                'cards' : 'credit cards payoff' , \\\n",
    "                'credit card payoff' : 'credit cards payoff' , \\\n",
    "                'credit pay off' : 'credit cards payoff' , \\\n",
    "                'credit payoff' : 'credit cards payoff' , \\\n",
    "                'credit loan' : 'credit cards payoff' , \\\n",
    "                'payoff' : 'credit cards payoff' , \\\n",
    "                'pay off' : 'credit cards payoff' , \\\n",
    "                'credit card paydown' : 'credit cards payoff' , \\\n",
    "                'credit card pay off' : 'credit cards payoff' ,\n",
    "                'personal loan' : 'perosonal purpose' , \\\n",
    "                'personal' : 'perosonal purpose' , \\\n",
    "                'wedding loan' : 'perosonal purpose' , \\\n",
    "                'getting ahead' : 'perosonal purpose' , \\\n",
    "                'vacation' : 'perosonal purpose' , \\\n",
    "                'major purchase' : 'perosonal purpose'  , \\\n",
    "                'car financing' : 'vehicle purpose' , \\\n",
    "                'car loan' : 'vehicle purpose' , \\\n",
    "                'debt' : 'debt payoff' , \\\n",
    "                'get out of debt' : 'debt payoff' , \\\n",
    "                'debt loan' : 'debt payoff' , \\\n",
    "                'get debt free' : 'debt payoff' , \\\n",
    "                'debt payoff' : 'debt payoff' , \\\n",
    "                'debt free' : 'debt payoff' , \\\n",
    "                'freedom' : 'debt payoff' , \\\n",
    "                'relief' : 'debt payoff' , \\\n",
    "                'debt reduction' : 'debt payoff' , \\\n",
    "                'bill consolidation' : 'bill payoff' , \\\n",
    "                'bill payoff' : 'bill payoff' , \\\n",
    "                'pay off bills' : 'bill payoff' , \\\n",
    "                'bills' : 'bill payoff'  , \\\n",
    "                'other' : 'other purpose' , \\\n",
    "                'loan 1' : 'other purpose' , \\\n",
    "                'loan1' : 'other purpose' , \\\n",
    "                'loan' : 'other purpose' , \\\n",
    "                'myloan' : 'other purpose' , \\\n",
    "                'my loan' : 'other purpose' }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(map_dict, inplace=True)\n",
    "len(df['Loan Title'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colunas = ['Home Ownership', 'Interest Rate', 'Inquires - six months', 'Total Accounts',\n",
    "               'Total Received Interest', 'Total Received Late Fee', 'Recoveries', \n",
    "               'Collection Recovery Fee', 'Collection 12 months Medical', \n",
    "               'Total Collection Amount', 'Total Revolving Credit Limit']\n",
    "\n",
    "#Loop em relação as features\n",
    "for coluna in colunas:\n",
    "  Q1 = df[coluna].quantile(q = 0.25) #Definindo o primeiro quartil\n",
    "  Q3 = df[coluna].quantile(q = 0.75) #Definindo o segundo quartil\n",
    "  IQR = Q3 - Q1 #Definindo o interquartil\n",
    "  superior = Q3 + IQR  #Definindo o Limite Superior\n",
    "  inferior = Q1 - IQR #Definindo o Limite Inferior\n",
    "\n",
    "  #Eliminando os outliers acima do limite superior\n",
    "  df.drop( df.loc[ df[coluna] > superior ].index, axis = 0, inplace = True )\n",
    "\n",
    "  #Eliminando os outliers abaixo do limite inferior\n",
    "  df.drop( df.loc[ df[coluna] < inferior ].index, axis = 0, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan Amount  Funded Amount  Funded Amount Investor  Term  Interest Rate  \\\n",
      "1          3609          11940            12191.996920    59      12.237563   \n",
      "7         20744          10609             7645.014802    58      13.993688   \n",
      "8          9299          11238            13429.456610    59      11.178457   \n",
      "9         19232           8962             7004.097481    58       5.520413   \n",
      "11        16581           8767            10637.049030    59       9.535988   \n",
      "\n",
      "   Grade Sub Grade Employment Duration  Home Ownership Verification Status  \\\n",
      "1      C        D3                RENT     39833.92100     Source Verified   \n",
      "7      A        A5                 OWN     61723.52014        Not Verified   \n",
      "8      G        C2            MORTGAGE     63205.09072            Verified   \n",
      "9      C        B5                RENT     42015.46586     Source Verified   \n",
      "11     A        D4            MORTGAGE     39605.50605     Source Verified   \n",
      "\n",
      "    ... Initial List Status  Total Received Interest  Total Received Late Fee  \\\n",
      "1   ...                   f               772.769385                 0.036181   \n",
      "7   ...                   w              1350.245212                 0.044965   \n",
      "8   ...                   w              4140.198978                 0.017106   \n",
      "9   ...                   f              2149.666963                 0.008338   \n",
      "11  ...                   w              1276.258125                 0.029185   \n",
      "\n",
      "    Recoveries  Collection Recovery Fee  Last week Pay  \\\n",
      "1     2.377215                 0.974821            109   \n",
      "7     0.098448                 0.047589             87   \n",
      "8     0.530214                 0.216985            144   \n",
      "9     2.912215                 0.886864              9   \n",
      "11    7.742979                 1.120056             55   \n",
      "\n",
      "    Total Collection Amount  Total Current Balance  \\\n",
      "1                        53                 182610   \n",
      "7                        48                 184909   \n",
      "8                        26                  68126   \n",
      "9                        35                  71650   \n",
      "11                       30                  33296   \n",
      "\n",
      "   Total Revolving Credit Limit  Loan Status  \n",
      "1                         20885            0  \n",
      "7                         43303            0  \n",
      "8                          7482            0  \n",
      "9                         14871            0  \n",
      "11                        11356            0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Collection 12 months Medical', 'Inquires - six months'], axis = 1, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"train_with_dummies_0_1.csv\")\n",
    "X = df.drop(['Loan Status'], axis = 1)\n",
    "y = df['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão: 0.5038045654785743\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[795 482]\n",
      " [757 463]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.62      0.56      1277\n",
      "           1       0.49      0.38      0.43      1220\n",
      "\n",
      "    accuracy                           0.50      2497\n",
      "   macro avg       0.50      0.50      0.49      2497\n",
      "weighted avg       0.50      0.50      0.50      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y_train,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#Normalização\n",
    "for col in X:\n",
    "    feature_range = (X_train[col].min(), X_train[col].max())\n",
    "    \n",
    "    if feature_range[0] < 0 or feature_range[1] > 1:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "        X_test[col] = scaler.transform(X_test[[col]])\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)  # Número de vizinhos\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisão: {accuracy}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do Modelo SVM:\n",
      "Precisão: 0.5062074489387265\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[641 636]\n",
      " [597 623]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51      1277\n",
      "           1       0.49      0.51      0.50      1220\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.51      0.51      0.51      2497\n",
      "weighted avg       0.51      0.51      0.51      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_model = SVC()  \n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(\"Resultados do Modelo SVM:\")\n",
    "print(f\"Precisão: {accuracy_svm}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix_svm)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Naive Bayes): 0.5158189827793352\n",
      "\n",
      "Matriz de Confusão (Naive Bayes):\n",
      "[[1143  134]\n",
      " [1075  145]]\n",
      "\n",
      "Relatório de Classificação (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.90      0.65      1277\n",
      "           1       0.52      0.12      0.19      1220\n",
      "\n",
      "    accuracy                           0.52      2497\n",
      "   macro avg       0.52      0.51      0.42      2497\n",
      "weighted avg       0.52      0.52      0.43      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_model = GaussianNB() \n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "class_report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"Precisão (Naive Bayes): {accuracy_nb}\")\n",
    "print(\"\\nMatriz de Confusão (Naive Bayes):\")\n",
    "print(conf_matrix_nb)\n",
    "print(\"\\nRelatório de Classificação (Naive Bayes):\")\n",
    "print(class_report_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Logistic Regression): 0.5102122547056468\n",
      "\n",
      "Matriz de Confusão (Logistic Regression):\n",
      "[[531 746]\n",
      " [477 743]]\n",
      "\n",
      "Relatório de Classificação (Logistic Regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.42      0.46      1277\n",
      "           1       0.50      0.61      0.55      1220\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.51      0.51      0.51      2497\n",
      "weighted avg       0.51      0.51      0.51      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo de Regressão Logística\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "class_report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Precisão (Logistic Regression): {accuracy_lr}\")\n",
    "print(\"\\nMatriz de Confusão (Logistic Regression):\")\n",
    "print(conf_matrix_lr)\n",
    "print(\"\\nRelatório de Classificação (Logistic Regression):\")\n",
    "print(class_report_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Bagging Classifier): 0.49939927913496196\n",
      "\n",
      "Matriz de Confusão (Bagging Classifier):\n",
      "[[782 495]\n",
      " [755 465]]\n",
      "\n",
      "Relatório de Classificação (Bagging Classifier):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.61      0.56      1277\n",
      "           1       0.48      0.38      0.43      1220\n",
      "\n",
      "    accuracy                           0.50      2497\n",
      "   macro avg       0.50      0.50      0.49      2497\n",
      "weighted avg       0.50      0.50      0.49      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Bagging Classifier\n",
    "bagging_model = BaggingClassifier()\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "conf_matrix_bagging = confusion_matrix(y_test, y_pred_bagging)\n",
    "class_report_bagging = classification_report(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"Precisão (Bagging Classifier): {accuracy_bagging}\")\n",
    "print(\"\\nMatriz de Confusão (Bagging Classifier):\")\n",
    "print(conf_matrix_bagging)\n",
    "print(\"\\nRelatório de Classificação (Bagging Classifier):\")\n",
    "print(class_report_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Random Forest): 0.5190228273928714\n",
      "\n",
      "Matriz de Confusão (Random Forest):\n",
      "[[674 603]\n",
      " [598 622]]\n",
      "\n",
      "Relatório de Classificação (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      1277\n",
      "           1       0.51      0.51      0.51      1220\n",
      "\n",
      "    accuracy                           0.52      2497\n",
      "   macro avg       0.52      0.52      0.52      2497\n",
      "weighted avg       0.52      0.52      0.52      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Precisão (Random Forest): {accuracy_rf}\")\n",
    "print(\"\\nMatriz de Confusão (Random Forest):\")\n",
    "print(conf_matrix_rf)\n",
    "print(\"\\nRelatório de Classificação (Random Forest):\")\n",
    "print(class_report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (AdaBoost): 0.527032438926712\n",
      "\n",
      "Matriz de Confusão (AdaBoost):\n",
      "[[653 624]\n",
      " [557 663]]\n",
      "\n",
      "Relatório de Classificação (AdaBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.53      1277\n",
      "           1       0.52      0.54      0.53      1220\n",
      "\n",
      "    accuracy                           0.53      2497\n",
      "   macro avg       0.53      0.53      0.53      2497\n",
      "weighted avg       0.53      0.53      0.53      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo AdaBoost\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "conf_matrix_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
    "class_report_adaboost = classification_report(y_test, y_pred_adaboost)\n",
    "\n",
    "print(f\"Precisão (AdaBoost): {accuracy_adaboost}\")\n",
    "print(\"\\nMatriz de Confusão (AdaBoost):\")\n",
    "print(conf_matrix_adaboost)\n",
    "print(\"\\nRelatório de Classificação (AdaBoost):\")\n",
    "print(class_report_adaboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Gradient Boosting): 0.527032438926712\n",
      "\n",
      "Matriz de Confusão (Gradient Boosting):\n",
      "[[614 663]\n",
      " [518 702]]\n",
      "\n",
      "Relatório de Classificação (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51      1277\n",
      "           1       0.51      0.58      0.54      1220\n",
      "\n",
      "    accuracy                           0.53      2497\n",
      "   macro avg       0.53      0.53      0.53      2497\n",
      "weighted avg       0.53      0.53      0.53      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Gradient Boosting\n",
    "gradientboost_model = GradientBoostingClassifier()\n",
    "gradientboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gradientboost = gradientboost_model.predict(X_test)\n",
    "\n",
    "accuracy_gradientboost = accuracy_score(y_test, y_pred_gradientboost)\n",
    "conf_matrix_gradientboost = confusion_matrix(y_test, y_pred_gradientboost)\n",
    "class_report_gradientboost = classification_report(y_test, y_pred_gradientboost)\n",
    "\n",
    "print(f\"Precisão (Gradient Boosting): {accuracy_gradientboost}\")\n",
    "print(\"\\nMatriz de Confusão (Gradient Boosting):\")\n",
    "print(conf_matrix_gradientboost)\n",
    "print(\"\\nRelatório de Classificação (Gradient Boosting):\")\n",
    "print(class_report_gradientboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (XGBoost): 0.5166199439327193\n",
      "\n",
      "Matriz de Confusão (XGBoost):\n",
      "[[654 623]\n",
      " [584 636]]\n",
      "\n",
      "Relatório de Classificação (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52      1277\n",
      "           1       0.51      0.52      0.51      1220\n",
      "\n",
      "    accuracy                           0.52      2497\n",
      "   macro avg       0.52      0.52      0.52      2497\n",
      "weighted avg       0.52      0.52      0.52      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo XGBoost\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgboost = xgboost_model.predict(X_test)\n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "conf_matrix_xgboost = confusion_matrix(y_test, y_pred_xgboost)\n",
    "class_report_xgboost = classification_report(y_test, y_pred_xgboost)\n",
    "\n",
    "print(f\"Precisão (XGBoost): {accuracy_xgboost}\")\n",
    "print(\"\\nMatriz de Confusão (XGBoost):\")\n",
    "print(conf_matrix_xgboost)\n",
    "print(\"\\nRelatório de Classificação (XGBoost):\")\n",
    "print(class_report_xgboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5021, number of negative: 4964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4213\n",
      "[LightGBM] [Info] Number of data points in the train set: 9985, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502854 -> initscore=0.011417\n",
      "[LightGBM] [Info] Start training from score 0.011417\n",
      "Precisão (LightGBM): 0.5206247496996396\n",
      "\n",
      "Matriz de Confusão (LightGBM):\n",
      "[[624 653]\n",
      " [544 676]]\n",
      "\n",
      "Relatório de Classificação (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51      1277\n",
      "           1       0.51      0.55      0.53      1220\n",
      "\n",
      "    accuracy                           0.52      2497\n",
      "   macro avg       0.52      0.52      0.52      2497\n",
      "weighted avg       0.52      0.52      0.52      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo LightGBM\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "conf_matrix_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
    "class_report_lgb = classification_report(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"Precisão (LightGBM): {accuracy_lgb}\")\n",
    "print(\"\\nMatriz de Confusão (LightGBM):\")\n",
    "print(conf_matrix_lgb)\n",
    "print(\"\\nRelatório de Classificação (LightGBM):\")\n",
    "print(class_report_lgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
