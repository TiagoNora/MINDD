{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])\n",
    "df = df.drop(columns=['Payment Plan'])\n",
    "df = df.drop(columns=['Accounts Delinquent'])\n",
    "df = df.drop(columns=['Batch Enrolled'])\n",
    "df =df.drop(columns=['Application Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['debt consolidation', 'credit card refinancing',\n",
       "       'home improvement', 'credit consolidation', 'green loan', 'other',\n",
       "       'moving and relocation', 'credit cards', 'medical expenses',\n",
       "       'refinance', 'credit card consolidation', 'lending club',\n",
       "       'debt consolidation loan', 'major purchase', 'vacation',\n",
       "       'business', 'credit card payoff', 'credit card',\n",
       "       'credit card refi', 'personal loan', 'cc refi', 'consolidate',\n",
       "       'medical', 'loan 1', 'consolidation', 'card consolidation',\n",
       "       'car financing', 'debt', 'home buying', 'freedom', 'consolidated',\n",
       "       'get out of debt', 'consolidation loan', 'dept consolidation',\n",
       "       'personal', 'cards', 'bathroom', 'refi', 'credit card loan',\n",
       "       'credit card debt', 'house', 'debt consolidation 2013',\n",
       "       'debt loan', 'cc refinance', 'home', 'cc consolidation',\n",
       "       'credit card refinance', 'credit loan', 'payoff',\n",
       "       'bill consolidation', 'credit card paydown', 'credit card pay off',\n",
       "       'get debt free', 'myloan', 'credit pay off', 'my loan', 'loan',\n",
       "       'bill payoff', 'cc-refinance', 'debt reduction', 'medical loan',\n",
       "       'wedding loan', 'credit', 'pay off bills', 'refinance loan',\n",
       "       'debt payoff', 'car loan', 'pay off', 'pool', 'credit payoff',\n",
       "       'credit card refinance loan', 'cc loan', 'debt free', 'conso',\n",
       "       'home improvement loan', 'loan consolidation', 'lending loan',\n",
       "       'relief', 'cc', 'loan1', 'getting ahead', 'home loan', 'bills'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Loan Title'] = df['Loan Title'].str.lower()\n",
    "len(df['Loan Title'].unique())\n",
    "df['Loan Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {'Loan Title':{'debt consolidation':'debt consolidation', \\\n",
    "                'debt consolidation loan':'debt consolidation', \\\n",
    "                'debt consolidation 2013':'debt consolidation', \\\n",
    "                'dept consolidation':'debt consolidation' ,\n",
    "                'credit card refinancing':'credit card refinancing', \\\n",
    "                'refinance':'credit card refinancing', \\\n",
    "                'cc refinance':'credit card refinancing',\\\n",
    "                'credit card refinance':'credit card refinancing',\\\n",
    "                'cc-refinance':'credit card refinancing', \\\n",
    "                'refinance loan':'credit card refinancing', \\\n",
    "                'credit card refinance loan':'credit card refinancing',\\\n",
    "                'credit card refi':'credit card refinancing', \\\n",
    "                'cc refi':'credit card refinancing', \\\n",
    "                'refi':'credit card refinancing'  ,\n",
    "                'home improvement':'home improvement',\\\n",
    "                'home improvement loan':'home improvement',\\\n",
    "                'bathroom':'home improvement',\\\n",
    "                'pool':'home improvement' ,\n",
    "                'home buying':'home buy',\\\n",
    "                'house':'home buy',\\\n",
    "                'home':'home buy',\\\n",
    "                'home loan':'home buy' ,\n",
    "                'credit consolidation':'credit consolidation',\\\n",
    "                'consolidation loan':'credit consolidation',\\\n",
    "                'cc consolidation':'credit consolidation',\\\n",
    "                'conso':'credit consolidation',\\\n",
    "                'credit card consolidation':'credit consolidation',\\\n",
    "                'card consolidation':'credit consolidation',\\\n",
    "                'loan consolidation':'credit consolidation',\\\n",
    "                'consolidate':'credit consolidation',\\\n",
    "                'consolidated':'credit consolidation' ,\n",
    "                'medical':'medical purpose',\\\n",
    "                'medical expenses':'medical purpose',\\\n",
    "                'medical loan':'medical purpose'  ,\n",
    "                'lending club' : 'lending purpose' , \\\n",
    "                'lending loan' : 'lending purpose'  ,\n",
    "                'business' : 'business purpose' , \\\n",
    "                'green loan' : 'business purpose' , \\\n",
    "                'moving and relocation' : 'business purpose'  , \\\n",
    "                'credit cards' : 'credit cards payoff' , \\\n",
    "                'credit card' : 'credit cards payoff' , \\\n",
    "                'credit card loan' : 'credit cards payoff' , \\\n",
    "                'credit' : 'credit cards payoff' , \\\n",
    "                'credit card debt' : 'credit cards payoff' , \\\n",
    "                'cc loan' : 'credit cards payoff' , \\\n",
    "                'cc' : 'credit cards payoff' , \\\n",
    "                'cards' : 'credit cards payoff' , \\\n",
    "                'credit card payoff' : 'credit cards payoff' , \\\n",
    "                'credit pay off' : 'credit cards payoff' , \\\n",
    "                'credit payoff' : 'credit cards payoff' , \\\n",
    "                'credit loan' : 'credit cards payoff' , \\\n",
    "                'payoff' : 'credit cards payoff' , \\\n",
    "                'pay off' : 'credit cards payoff' , \\\n",
    "                'credit card paydown' : 'credit cards payoff' , \\\n",
    "                'credit card pay off' : 'credit cards payoff' ,\n",
    "                'personal loan' : 'perosonal purpose' , \\\n",
    "                'personal' : 'perosonal purpose' , \\\n",
    "                'wedding loan' : 'perosonal purpose' , \\\n",
    "                'getting ahead' : 'perosonal purpose' , \\\n",
    "                'vacation' : 'perosonal purpose' , \\\n",
    "                'major purchase' : 'perosonal purpose'  , \\\n",
    "                'car financing' : 'vehicle purpose' , \\\n",
    "                'car loan' : 'vehicle purpose' , \\\n",
    "                'debt' : 'debt payoff' , \\\n",
    "                'get out of debt' : 'debt payoff' , \\\n",
    "                'debt loan' : 'debt payoff' , \\\n",
    "                'get debt free' : 'debt payoff' , \\\n",
    "                'debt payoff' : 'debt payoff' , \\\n",
    "                'debt free' : 'debt payoff' , \\\n",
    "                'freedom' : 'debt payoff' , \\\n",
    "                'relief' : 'debt payoff' , \\\n",
    "                'debt reduction' : 'debt payoff' , \\\n",
    "                'bill consolidation' : 'bill payoff' , \\\n",
    "                'bill payoff' : 'bill payoff' , \\\n",
    "                'pay off bills' : 'bill payoff' , \\\n",
    "                'bills' : 'bill payoff'  , \\\n",
    "                'other' : 'other purpose' , \\\n",
    "                'loan 1' : 'other purpose' , \\\n",
    "                'loan1' : 'other purpose' , \\\n",
    "                'loan' : 'other purpose' , \\\n",
    "                'myloan' : 'other purpose' , \\\n",
    "                'my loan' : 'other purpose' }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(map_dict, inplace=True)\n",
    "len(df['Loan Title'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colunas = ['Home Ownership', 'Interest Rate', 'Inquires - six months', 'Total Accounts',\n",
    "               'Total Received Interest', 'Total Received Late Fee', 'Recoveries', \n",
    "               'Collection Recovery Fee', 'Collection 12 months Medical', \n",
    "               'Total Collection Amount', 'Total Revolving Credit Limit']\n",
    "\n",
    "#Loop em relação as features\n",
    "for coluna in colunas:\n",
    "  Q1 = df[coluna].quantile(q = 0.25) #Definindo o primeiro quartil\n",
    "  Q3 = df[coluna].quantile(q = 0.75) #Definindo o segundo quartil\n",
    "  IQR = Q3 - Q1 #Definindo o interquartil\n",
    "  superior = Q3 + IQR  #Definindo o Limite Superior\n",
    "  inferior = Q1 - IQR #Definindo o Limite Inferior\n",
    "\n",
    "  #Eliminando os outliers acima do limite superior\n",
    "  df.drop( df.loc[ df[coluna] > superior ].index, axis = 0, inplace = True )\n",
    "\n",
    "  #Eliminando os outliers abaixo do limite inferior\n",
    "  df.drop( df.loc[ df[coluna] < inferior ].index, axis = 0, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan Amount  Funded Amount  Funded Amount Investor  Term  Interest Rate  \\\n",
      "1          3609          11940            12191.996920    59      12.237563   \n",
      "7         20744          10609             7645.014802    58      13.993688   \n",
      "8          9299          11238            13429.456610    59      11.178457   \n",
      "9         19232           8962             7004.097481    58       5.520413   \n",
      "11        16581           8767            10637.049030    59       9.535988   \n",
      "\n",
      "   Grade Sub Grade Employment Duration  Home Ownership Verification Status  \\\n",
      "1      C        D3                RENT     39833.92100     Source Verified   \n",
      "7      A        A5                 OWN     61723.52014        Not Verified   \n",
      "8      G        C2            MORTGAGE     63205.09072            Verified   \n",
      "9      C        B5                RENT     42015.46586     Source Verified   \n",
      "11     A        D4            MORTGAGE     39605.50605     Source Verified   \n",
      "\n",
      "    ... Initial List Status  Total Received Interest  Total Received Late Fee  \\\n",
      "1   ...                   f               772.769385                 0.036181   \n",
      "7   ...                   w              1350.245212                 0.044965   \n",
      "8   ...                   w              4140.198978                 0.017106   \n",
      "9   ...                   f              2149.666963                 0.008338   \n",
      "11  ...                   w              1276.258125                 0.029185   \n",
      "\n",
      "    Recoveries  Collection Recovery Fee  Last week Pay  \\\n",
      "1     2.377215                 0.974821            109   \n",
      "7     0.098448                 0.047589             87   \n",
      "8     0.530214                 0.216985            144   \n",
      "9     2.912215                 0.886864              9   \n",
      "11    7.742979                 1.120056             55   \n",
      "\n",
      "    Total Collection Amount  Total Current Balance  \\\n",
      "1                        53                 182610   \n",
      "7                        48                 184909   \n",
      "8                        26                  68126   \n",
      "9                        35                  71650   \n",
      "11                       30                  33296   \n",
      "\n",
      "   Total Revolving Credit Limit  Loan Status  \n",
      "1                         20885            0  \n",
      "7                         43303            0  \n",
      "8                          7482            0  \n",
      "9                         14871            0  \n",
      "11                        11356            0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Collection 12 months Medical', 'Inquires - six months'], axis = 1, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"train_with_dummies_0_1.csv\")\n",
    "X = df.drop(['Loan Status'], axis = 1)\n",
    "y = df['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loan Amount  Funded Amount  Funded Amount Investor  Term  Interest Rate  \\\n",
      "0        10000          32236             12329.36286    59      11.135007   \n",
      "1         3609          11940             12191.99692    59      12.237563   \n",
      "2        28276           9311             21603.22455    59      12.545884   \n",
      "3        11170           6954             17877.15585    59      16.731201   \n",
      "4        16890          13226             13539.92667    59      15.008300   \n",
      "\n",
      "   Home Ownership.1  Debit to Income  Delinquency - two years  \\\n",
      "0      176346.62670        16.284758                        1   \n",
      "1       39833.92100        15.412409                        0   \n",
      "2       91506.69105        28.137619                        0   \n",
      "3      108286.57590        18.043730                        1   \n",
      "4       44234.82545        17.209886                        1   \n",
      "\n",
      "   Inquires - six months  Open Account  ...  Loan Title_personalloan  \\\n",
      "0                      0            13  ...                        0   \n",
      "1                      0            12  ...                        0   \n",
      "2                      0            14  ...                        0   \n",
      "3                      0             7  ...                        0   \n",
      "4                      3            13  ...                        0   \n",
      "\n",
      "   Loan Title_pool  Loan Title_refi  Loan Title_refinance  \\\n",
      "0                0                0                     0   \n",
      "1                0                0                     0   \n",
      "2                0                0                     0   \n",
      "3                0                0                     0   \n",
      "4                0                0                     0   \n",
      "\n",
      "   Loan Title_refinanceloan  Loan Title_relief  Loan Title_vacation  \\\n",
      "0                         0                  0                    0   \n",
      "1                         0                  0                    0   \n",
      "2                         0                  0                    0   \n",
      "3                         0                  0                    0   \n",
      "4                         0                  0                    0   \n",
      "\n",
      "   Loan Title_weddingloan  Initial List Status_w  Application Type_joint  \n",
      "0                       0                      1                       0  \n",
      "1                       0                      0                       0  \n",
      "2                       0                      1                       0  \n",
      "3                       0                      1                       0  \n",
      "4                       0                      1                       0  \n",
      "\n",
      "[5 rows x 147 columns]\n",
      "Precisão: 0.4889867841409692\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[784 493]\n",
      " [783 437]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55      1277\n",
      "           1       0.47      0.36      0.41      1220\n",
      "\n",
      "    accuracy                           0.49      2497\n",
      "   macro avg       0.49      0.49      0.48      2497\n",
      "weighted avg       0.49      0.49      0.48      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y_train,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#Normalização\n",
    "for col in X:\n",
    "    feature_range = (X_train[col].min(), X_train[col].max())\n",
    "    \n",
    "    if feature_range[0] < 0 or feature_range[1] > 1:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "        X_test[col] = scaler.transform(X_test[[col]])\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)  # Número de vizinhos\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisão: {accuracy}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do Modelo SVM:\n",
      "Precisão: 0.500600720865038\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[640 637]\n",
      " [610 610]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.50      0.51      1277\n",
      "           1       0.49      0.50      0.49      1220\n",
      "\n",
      "    accuracy                           0.50      2497\n",
      "   macro avg       0.50      0.50      0.50      2497\n",
      "weighted avg       0.50      0.50      0.50      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_model = SVC()  \n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(\"Resultados do Modelo SVM:\")\n",
    "print(f\"Precisão: {accuracy_svm}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix_svm)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Naive Bayes): 0.5058069683620344\n",
      "\n",
      "Matriz de Confusão (Naive Bayes):\n",
      "[[1034  243]\n",
      " [ 991  229]]\n",
      "\n",
      "Relatório de Classificação (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.63      1277\n",
      "           1       0.49      0.19      0.27      1220\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.50      0.50      0.45      2497\n",
      "weighted avg       0.50      0.51      0.45      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_model = GaussianNB() \n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "class_report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"Precisão (Naive Bayes): {accuracy_nb}\")\n",
    "print(\"\\nMatriz de Confusão (Naive Bayes):\")\n",
    "print(conf_matrix_nb)\n",
    "print(\"\\nRelatório de Classificação (Naive Bayes):\")\n",
    "print(class_report_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Logistic Regression): 0.48338005606728074\n",
      "\n",
      "Matriz de Confusão (Logistic Regression):\n",
      "[[434 843]\n",
      " [447 773]]\n",
      "\n",
      "Relatório de Classificação (Logistic Regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.34      0.40      1277\n",
      "           1       0.48      0.63      0.55      1220\n",
      "\n",
      "    accuracy                           0.48      2497\n",
      "   macro avg       0.49      0.49      0.47      2497\n",
      "weighted avg       0.49      0.48      0.47      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo de Regressão Logística\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "class_report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Precisão (Logistic Regression): {accuracy_lr}\")\n",
    "print(\"\\nMatriz de Confusão (Logistic Regression):\")\n",
    "print(conf_matrix_lr)\n",
    "print(\"\\nRelatório de Classificação (Logistic Regression):\")\n",
    "print(class_report_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Bagging Classifier): 0.5170204245094113\n",
      "\n",
      "Matriz de Confusão (Bagging Classifier):\n",
      "[[786 491]\n",
      " [715 505]]\n",
      "\n",
      "Relatório de Classificação (Bagging Classifier):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.62      0.57      1277\n",
      "           1       0.51      0.41      0.46      1220\n",
      "\n",
      "    accuracy                           0.52      2497\n",
      "   macro avg       0.52      0.51      0.51      2497\n",
      "weighted avg       0.52      0.52      0.51      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Bagging Classifier\n",
    "bagging_model = BaggingClassifier()\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "conf_matrix_bagging = confusion_matrix(y_test, y_pred_bagging)\n",
    "class_report_bagging = classification_report(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"Precisão (Bagging Classifier): {accuracy_bagging}\")\n",
    "print(\"\\nMatriz de Confusão (Bagging Classifier):\")\n",
    "print(conf_matrix_bagging)\n",
    "print(\"\\nRelatório de Classificação (Bagging Classifier):\")\n",
    "print(class_report_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Random Forest): 0.4921906287545054\n",
      "\n",
      "Matriz de Confusão (Random Forest):\n",
      "[[633 644]\n",
      " [624 596]]\n",
      "\n",
      "Relatório de Classificação (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50      1277\n",
      "           1       0.48      0.49      0.48      1220\n",
      "\n",
      "    accuracy                           0.49      2497\n",
      "   macro avg       0.49      0.49      0.49      2497\n",
      "weighted avg       0.49      0.49      0.49      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Precisão (Random Forest): {accuracy_rf}\")\n",
    "print(\"\\nMatriz de Confusão (Random Forest):\")\n",
    "print(conf_matrix_rf)\n",
    "print(\"\\nRelatório de Classificação (Random Forest):\")\n",
    "print(class_report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (AdaBoost): 0.5022026431718062\n",
      "\n",
      "Matriz de Confusão (AdaBoost):\n",
      "[[647 630]\n",
      " [613 607]]\n",
      "\n",
      "Relatório de Classificação (AdaBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51      1277\n",
      "           1       0.49      0.50      0.49      1220\n",
      "\n",
      "    accuracy                           0.50      2497\n",
      "   macro avg       0.50      0.50      0.50      2497\n",
      "weighted avg       0.50      0.50      0.50      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo AdaBoost\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "conf_matrix_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
    "class_report_adaboost = classification_report(y_test, y_pred_adaboost)\n",
    "\n",
    "print(f\"Precisão (AdaBoost): {accuracy_adaboost}\")\n",
    "print(\"\\nMatriz de Confusão (AdaBoost):\")\n",
    "print(conf_matrix_adaboost)\n",
    "print(\"\\nRelatório de Classificação (AdaBoost):\")\n",
    "print(class_report_adaboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (Gradient Boosting): 0.5330396475770925\n",
      "\n",
      "Matriz de Confusão (Gradient Boosting):\n",
      "[[656 621]\n",
      " [545 675]]\n",
      "\n",
      "Relatório de Classificação (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.51      0.53      1277\n",
      "           1       0.52      0.55      0.54      1220\n",
      "\n",
      "    accuracy                           0.53      2497\n",
      "   macro avg       0.53      0.53      0.53      2497\n",
      "weighted avg       0.53      0.53      0.53      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Gradient Boosting\n",
    "gradientboost_model = GradientBoostingClassifier()\n",
    "gradientboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gradientboost = gradientboost_model.predict(X_test)\n",
    "\n",
    "accuracy_gradientboost = accuracy_score(y_test, y_pred_gradientboost)\n",
    "conf_matrix_gradientboost = confusion_matrix(y_test, y_pred_gradientboost)\n",
    "class_report_gradientboost = classification_report(y_test, y_pred_gradientboost)\n",
    "\n",
    "print(f\"Precisão (Gradient Boosting): {accuracy_gradientboost}\")\n",
    "print(\"\\nMatriz de Confusão (Gradient Boosting):\")\n",
    "print(conf_matrix_gradientboost)\n",
    "print(\"\\nRelatório de Classificação (Gradient Boosting):\")\n",
    "print(class_report_gradientboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão (XGBoost): 0.5098117741289547\n",
      "\n",
      "Matriz de Confusão (XGBoost):\n",
      "[[633 644]\n",
      " [580 640]]\n",
      "\n",
      "Relatório de Classificação (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51      1277\n",
      "           1       0.50      0.52      0.51      1220\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.51      0.51      0.51      2497\n",
      "weighted avg       0.51      0.51      0.51      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "C:\\Users\\jgasp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo XGBoost\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgboost = xgboost_model.predict(X_test)\n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "conf_matrix_xgboost = confusion_matrix(y_test, y_pred_xgboost)\n",
    "class_report_xgboost = classification_report(y_test, y_pred_xgboost)\n",
    "\n",
    "print(f\"Precisão (XGBoost): {accuracy_xgboost}\")\n",
    "print(\"\\nMatriz de Confusão (XGBoost):\")\n",
    "print(conf_matrix_xgboost)\n",
    "print(\"\\nRelatório de Classificação (XGBoost):\")\n",
    "print(class_report_xgboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5021, number of negative: 4964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4214\n",
      "[LightGBM] [Info] Number of data points in the train set: 9985, number of used features: 79\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502854 -> initscore=0.011417\n",
      "[LightGBM] [Info] Start training from score 0.011417\n",
      "Precisão (LightGBM): 0.5338406087304766\n",
      "\n",
      "Matriz de Confusão (LightGBM):\n",
      "[[682 595]\n",
      " [569 651]]\n",
      "\n",
      "Relatório de Classificação (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54      1277\n",
      "           1       0.52      0.53      0.53      1220\n",
      "\n",
      "    accuracy                           0.53      2497\n",
      "   macro avg       0.53      0.53      0.53      2497\n",
      "weighted avg       0.53      0.53      0.53      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Instanciando o objeto RandomUnderSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = rus.fit_resample(X, y)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_train,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo LightGBM\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "conf_matrix_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
    "class_report_lgb = classification_report(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"Precisão (LightGBM): {accuracy_lgb}\")\n",
    "print(\"\\nMatriz de Confusão (LightGBM):\")\n",
    "print(conf_matrix_lgb)\n",
    "print(\"\\nRelatório de Classificação (LightGBM):\")\n",
    "print(class_report_lgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
